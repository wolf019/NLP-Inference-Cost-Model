{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3facdb-b335-4561-a244-a9075a4fdc04",
   "metadata": {},
   "source": [
    "The aim of this notebook is to fine tune a BERT pretrained model for text classification.\n",
    "\n",
    "- **Model:** https://huggingface.co/bert-base-uncased\n",
    "- **Dataset:** https://huggingface.co/datasets/ag_news\n",
    "\n",
    "**Guide**: https://huggingface.co/docs/transformers/traininghttps://huggingface.co/docs/transformers/training\n",
    "\n",
    "**Authors**\n",
    "\n",
    "    - Tom Axberg (taxberg@kth.se)\n",
    "    - Antonio Nieto (antonio.nieto@datatonic.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea94dc3-c0ac-4965-9b08-54ea6050bc37",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a503ae-59f5-4c58-ae79-766ca124396c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "!pip install transformers datasets numpy torch tensorflow ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e23e1d-c566-42bd-8e15-6f5e9260ca50",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f143f1f-0806-4109-844c-40c590af5fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomaxberg/opt/anaconda3/envs/tf-metal/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers.file_utils import is_tf_available, is_torch_available\n",
    "from transformers import RobertaTokenizerFast, TFAutoModelForSequenceClassification #OBS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa25e1-7d49-4cc9-bb62-255776a80e16",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbcfefe-8068-4d9f-9870-7ae6707179a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4395cc-93e5-4e8f-b4d7-39158c736152",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ebf08c-c792-496b-b73e-6dafe71c1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ag_news'\n",
    "num_targets = 4 \n",
    "model_name = \"roberta-base\"\n",
    "max_length = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca5133-3277-4731-8601-623cad9a2b67",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecee7cc-d0e3-4828-a21a-cf9a9f00f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    }
   ],
   "source": [
    "# Manually specify the number of unique targets\n",
    "train_dataset = load_dataset(dataset_name, split=\"train[10%:]\")\n",
    "val_dataset = load_dataset(dataset_name, split=\"train[:10%]\")\n",
    "test_dataset = load_dataset(dataset_name, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a277ae-c053-48d6-9c11-f1b90e3fc646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 108000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0004b972-22be-40d9-95cb-9e79add91b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'RocketInfo Partners with Canadian Press, Helps Nascar RocketInfo Partners with Canadian Press, Helps Nascar\\\\\\\\Rocketinfo Inc., news search engine announced yesterday that it has formed a key reseller alliance with the Canadian Press (CP), one of the top-rated multimedia news agencies in the world. CP plans to expand their media monitoring services by offering clients access to the ...',\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c97026-a0b2-47fd-bed4-7aaf7e354944",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c34d4b3-f443-42cf-b22a-4132ae67f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer (convert our text to sequence of tokens)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fab4359-54a8-4302-a813-555db5918cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-05d0c53da221e9aa.arrow\n",
      "Loading cached processed dataset at /Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-911e8fa04cd1023a.arrow\n",
      "Loading cached processed dataset at /Users/tomaxberg/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548/cache-f343d3eb7887bcbe.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset, truncate when passed 'max_length' and pad with 0's when less than 'max_length'\n",
    "train_tokenized = train_dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)\n",
    "val_tokenized = val_dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)\n",
    "test_tokenized = test_dataset.map(lambda x: tokenizer(x['text'], truncation=True, padding='max_length'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d87a331-3221-484b-937c-a28f18f08047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 108000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bbcaae-5195-4511-90aa-65b714c74b52",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500be08c-7de0-49e8-8cfe-a6148fb8c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 560\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 2.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:59:03.911377: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-01 20:59:03.911973: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-01 20:59:03.912249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# get data in standard tf.data.Dataset and remove 'text' label as it is not longer needed\n",
    "tf_train_dataset = train_tokenized.remove_columns(['text']).with_format('tensorflow')\n",
    "tf_val_dataset = val_tokenized.remove_columns(['text']).with_format('tensorflow')\n",
    "tf_test_dataset = test_tokenized.remove_columns(['text']).with_format('tensorflow')\n",
    "\n",
    "# convert to tensors\n",
    "train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
    "train_tf_dataset = train_tf_dataset.shuffle(len(tf_train_dataset)).batch(8)\n",
    "\n",
    "val_features = {x: tf_val_dataset[x] for x in tokenizer.model_input_names}\n",
    "val_tf_dataset = tf.data.Dataset.from_tensor_slices((val_features, tf_val_dataset[\"label\"]))\n",
    "val_tf_dataset = val_tf_dataset.shuffle(len(val_tf_dataset)).batch(8)\n",
    "\n",
    "test_features = {x: tf_test_dataset[x] for x in tokenizer.model_input_names}\n",
    "test_tf_dataset = tf.data.Dataset.from_tensor_slices((test_features, tf_test_dataset[\"label\"]))\n",
    "test_tf_dataset = test_tf_dataset.shuffle(len(test_tf_dataset)).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b251f-1e99-4817-b13f-601e44920288",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62df12b4-4b76-42a4-ae52-63e773a61f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the model (pre-trained weights)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4a64e4-eb36-4aa3-a455-69706d83a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 07:45:04.366719: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500/13500 [==============================] - 13144s 972ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3393 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 2/3\n",
      "13500/13500 [==============================] - 13103s 971ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.3337 - val_sparse_categorical_accuracy: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa379429a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy()\n",
    ")\n",
    "\n",
    "model.fit(train_tf_dataset, validation_data=val_tf_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5e3761-c734-4486-9f07-742fecd3e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"../models/{model_name}-trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a35504-d973-4685-a6c9-99e5ba4d277c",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad9e29f-e3ad-420b-a147-078e96d25edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_targets)\n",
    "model.load_weights(f\"../models/{model_name}-trained/tf_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9a544-91e5-4776-b7c4-25d88b652068",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35cfec1-8a07-4b9a-8475-a4cba6212df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label is: 0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Fears for T N pension after talks Unions representing workers at Turner Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"\n",
    "input_text_tokenized = tokenizer.encode(input_text,\n",
    "                                        truncation=True,\n",
    "                                        padding=True,\n",
    "                                        return_tensors=\"tf\")\n",
    "prediction = model(input_text_tokenized)\n",
    "prediction_logits = prediction[0]\n",
    "prediction_probs = tf.nn.softmax(prediction_logits,axis=1).numpy()\n",
    "print(f'The predicted label is: {np.argmax(prediction_probs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adccf126-1739-4d78-9c81-312cad9cac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"../models/{model_name}-trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28e2012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:59:22.217630: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 2737s 3s/step - loss: 1.3864 - sparse_categorical_accuracy: 0.2500\n",
      "test loss, test acc: [1.386419415473938, 0.2499999850988388]\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy()\n",
    ")\n",
    "result = model.evaluate(test_tf_dataset)\n",
    "print(\"test loss, test acc:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386cc1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
